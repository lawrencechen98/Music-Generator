{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x12c3a34e0>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11914e438>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11eec7f60>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x1272227f0>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11de66d30>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11de9e438>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f5dbb70>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x1222b9320>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f2d79e8>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f029eb8>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x1070683c8>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f915358>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11fb848d0>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f2b7860>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x12266d358>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x12554df28>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x107009e80>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x106fad6d8>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x124f59b38>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f01aa90>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11f599518>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x12184cc88>\n",
      "Extracting MIDI FIle: \n",
      "<music21.stream.Score 0x11eea0320>\n"
     ]
    }
   ],
   "source": [
    "notes_corpus = []\n",
    "\n",
    "for file in glob.glob(\"midi/*.mid\"):\n",
    "    \n",
    "    print(\"Extracting MIDI FIle: \")\n",
    "    midi_stream = converter.parse(file)\n",
    "    print(midi_stream)\n",
    "\n",
    "    notes = None\n",
    "\n",
    "    partition = instrument.partitionByInstrument(midi_stream)\n",
    "\n",
    "    if partition: \n",
    "        notes = partition.parts[0].recurse()\n",
    "    else: \n",
    "        notes = midi_stream.flat.notes\n",
    "\n",
    "    for element in notes:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes_corpus.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes_corpus.append('.'.join(str(n) for n in element.normalOrder))           \n",
    "\n",
    "with open('data/notes_corpus', 'wb') as filepath:\n",
    "    pickle.dump(notes_corpus, filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(set(notes_corpus))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 150\n",
    "note_sequence_input = []\n",
    "next_note_output = []\n",
    "\n",
    "notes = sorted(set(notes_corpus))\n",
    "note2int = dict((note, num) for num, note in enumerate(notes))\n",
    "\n",
    "for i in range(0, len(notes_corpus) - window_size):\n",
    "    current_sequence = [note2int[note] for note in notes_corpus[i:window_size+i]]\n",
    "    next_note = note2int[notes_corpus[window_size+i]]\n",
    "    note_sequence_input.append(current_sequence)\n",
    "    next_note_output.append(next_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = numpy.reshape(note_sequence_input, (len(note_sequence_input), window_size))\n",
    "training_data = training_data / float(vocab_size)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11753, 219)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label = np_utils.to_categorical(next_note_output)\n",
    "training_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(500, input_shape=(training_data.shape[1], training_data.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(500, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(500))\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "history = History()\n",
    "callbacks_list = [model_checkpoint, history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  640/11753 [>.............................] - ETA: 34:55 - loss: 5.1638"
     ]
    }
   ],
   "source": [
    "model.fit(training_data, training_label, epochs=200, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
